from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from dotenv import load_dotenv

from .vector_store  import VectorStorageManager


class RAGChain:
    load_dotenv()

    def __init__(self, vector_store: VectorStorageManager):
        self.vector_store = vector_store
        self.llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)

        self.prompt = ChatPromptTemplate.from_template(                                                                       
              """Answer the question based only on the following context:                                                       

                {context}                                                                                                                     

                Question: {question}                                                                                                          
                                                                                                                                                
            Answer:"""                                                                                                                    
        )

    def query(self, question: str, k: int = 4) -> str:                                                                            
        """                                                                                                                       
            Ask a question and get an answer based on your documents.                                                                 
                                                                                                                                    
            Args:                                                                                                                     
                question: The question to ask                                                                                         
                k: Number of documents to retrieve for context                                                                        
                                                                                                                                    
            Returns:                                                                                                                  
                Answer string generated by the LLM                                                                                    
        """                                                                                                               
        # Step 1: Retrieve relevant documents                                                                                     
        docs = self.vector_store.similarity_search(question, k=k)                                                                 
                                                                                                                   
        # Step 2: Format documents into a single context string                                                                   
        context = "\n\n".join([doc.page_content for doc in docs])                                                                 
                                                                                                  
        # Step 3: Build and run the chain                                                                                         
        chain = self.prompt | self.llm | StrOutputParser()                                                                        
                                                                                                                                
        # Step 4: Invoke with our context and question                                                                            
        answer = chain.invoke({                                                                                                   
            "context": context,                                                                                                   
            "question": question                                                                                                  
        })                                                                                                                        
                                                                                                                                
        return answer                                                                                                             
                                                                                                                                                                  